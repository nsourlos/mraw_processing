{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and global vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import torchvision.transforms \n",
    "import cv2\n",
    "import gc\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "\n",
    "from torchvision.io import decode_image\n",
    "from pathlib import Path\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "from typing import Union\n",
    "\n",
    "# pyplot style\n",
    "plt.rcParams[\"savefig.bbox\"] = 'tight'\n",
    "# Select data path\n",
    "# DATA_PATH = Path('../../data/raw/test_data')\n",
    "DATA_PATH = Path('../../data/raw/back_h0_128mm_test015')\n",
    "# Colormap\n",
    "cmap1_strict = matplotlib.colors.ListedColormap(['green'])\n",
    "# Number of images used for testing\n",
    "max_number_of_images = 709\n",
    "# Convolutional network\n",
    "conv_fn = tf.nn.conv2d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian and sobel kernel calculations functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gaussian_filter(sigma:float=1.4, k:int=2):\n",
    "    \"\"\"\n",
    "    Creates a gaussian kernel with determined sigma and size values\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sigma : float\n",
    "        The standard deviation of the gaussian\n",
    "\n",
    "    k : int\n",
    "        The size of the kernel\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tf.constant\n",
    "        The filter as a constant tensorflow value\n",
    "    \"\"\"\n",
    "    size = (2*k)+1\n",
    "    kernel = np.fromfunction(lambda x, y:(math.e ** (-(((x-(k))**2) + ((y-(k))**2))/(2*sigma**2)))/(2*math.pi*sigma**2), (size, size))\n",
    "    return tf.constant(kernel)\n",
    "def create_sobel_kernel(k=3, transposed = False):\n",
    "    \"\"\"\n",
    "    Creates a sobel kernel with determined size value\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    k : int\n",
    "        The size of the kernel\n",
    "\n",
    "    transposed : bool\n",
    "        Should the kernel be transposed\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tf.constant\n",
    "        The filter as a constant tensorflow value\n",
    "    \"\"\"\n",
    "    grid_range = np.linspace(-(k // 2), k // 2, k)\n",
    "    x, y = np.meshgrid(grid_range, grid_range)\n",
    "    numer = x\n",
    "    denom = (x**2 + y**2)\n",
    "    denom[:, k // 2] = 1\n",
    "    sobel_2D = numer / denom\n",
    "    return tf.constant(sobel_2D.T) if transposed else tf.constant(sobel_2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show example kernels\n",
    "kernel = [create_gaussian_filter(1.4,2), create_sobel_kernel(5, True)]\n",
    "for style in kernel:\n",
    "    plt.matshow(style)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Well known kernel examples and custom ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary with kernels\n",
    "kernels = {\n",
    "    \"Edge Detect\" : tf.constant([\n",
    "                    [-1,-1,-1],\n",
    "                    [-1,8,-1],\n",
    "                    [-1,-1,-1],\n",
    "                    ]),\n",
    "    \"Bottom Sobel\" : tf.constant([\n",
    "                    [-1,-2,-1],\n",
    "                    [0,0,0],\n",
    "                    [1,2,1],\n",
    "                    ]),\n",
    "    \"Top Sobel\" : tf.constant([\n",
    "        [1,2,1],\n",
    "        [0,0,0],\n",
    "        [-1,-2,-1],\n",
    "    ]),\n",
    "    \"Emboss\" : tf.constant([\n",
    "                    [-3,-2,-1],\n",
    "                    [1,0,-1],\n",
    "                    [3,2,1],\n",
    "                    ]),\n",
    "    \"Sharpen\" : tf.constant([\n",
    "                    [0,-1,0],\n",
    "                    [-1,5,-1],\n",
    "                    [0,-1,0],\n",
    "                    ]),\n",
    "    \"Mean\" : tf.constant([\n",
    "        [1, 1, 1],\n",
    "        [1, 1, 1],\n",
    "        [1, 1, 1]\n",
    "    ]),\n",
    "    \"Gaussian\" : tf.constant([\n",
    "        [1, 2, 1],\n",
    "        [2, 4, 2],\n",
    "        [1, 2, 1]\n",
    "    ]),\n",
    "    \"Smoothing 5x5\" : tf.constant([ #Its still just Gaussian filter\n",
    "        [2,4,5,4,2],\n",
    "        [4,9,12,9,4],\n",
    "        [5,12,15,12,5],\n",
    "        [4,9,12,9,4],\n",
    "        [2,4,5,4,2]\n",
    "    ]),\n",
    "    \"Top Sobel 5x5\" : tf.constant([\n",
    "        [2,2,4,2,2],\n",
    "        [1,1,2,1,1],\n",
    "        [0,0,0,0,0],\n",
    "        [-1,-1,-2,-1,-1],\n",
    "        [-2,-2,-4,-2,-2]\n",
    "    ]),\n",
    "    \"Bottom Sobel 5x5\" : tf.constant([\n",
    "        [-2,-2,-4,-2,-2],\n",
    "        [-1,-1,-2,-1,-1],\n",
    "        [0,0,0,0,0],\n",
    "        [1,1,2,1,1],\n",
    "        [2,2,4,2,2]\n",
    "    ]),\n",
    "    \"Custom2\" : tf.constant([\n",
    "        [-1, -1, -1],\n",
    "        [1, 1,  1],\n",
    "        [-1, -1, -1],\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Kernel keys list\n",
    "kernels_keys = list(kernels.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show kernels using matplotlib\n",
    "plt.figure(figsize=(16,16))\n",
    "fig, plots = plt.subplots(1, len(kernels))\n",
    "fig.suptitle('Examples of kernels')\n",
    "fig.set_figwidth(15)\n",
    "for i, (name, kernel) in enumerate(kernels.items()):\n",
    "    plots[i].matshow(kernel,)\n",
    "    plots[i].set_title(name)\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel and convolutional layer helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_work=None\n",
    "t2_not=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kernel(name:str=\"Edge Detect\") -> tf.Tensor:\n",
    "    \"\"\"\n",
    "    Gets the kernel from a dictionary and sets it to the correct shape\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    name : str\n",
    "        The name of the kernel within the previously defined kernels dictionary\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tf.Tensor\n",
    "        The kernel with the correct shape.\n",
    "    \"\"\"\n",
    "    krnl = kernels[name]\n",
    "    krnl = tf.reshape(krnl, [*krnl.shape, 1, 1])\n",
    "    return tf.cast(krnl, dtype=tf.float32)\n",
    "\n",
    "def filter_over_image(input_image:np.array, kernel:Union[tf.constant, str], normalize:bool = True) -> np.array:\n",
    "    \"\"\"\n",
    "    Gets the kernel from a dictionary and sets it to the correct shape\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_image : np.array\n",
    "        The image to be filtered over\n",
    "\n",
    "    kernel : tf.constant | str\n",
    "        The kernel as a tensorflow constant or as a string with the name of kernel from kernels dict\n",
    "\n",
    "    normalize : boolean\n",
    "        Boolean asking if the output should be normalized\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.array\n",
    "        The new transformed image\n",
    "    \"\"\"\n",
    "    if type(kernel) == str:\n",
    "        krnl = get_kernel(kernel)\n",
    "    else:\n",
    "        if len(kernel.shape) == 3:\n",
    "            krnl = tf.reshape(kernel, [kernel.shape[1], kernel.shape[2], 1, kernel.shape[0]])\n",
    "        else:\n",
    "            krnl = tf.reshape(kernel, [*kernel.shape, 1, 1])\n",
    "        krnl = tf.cast(krnl, dtype=tf.float32)\n",
    "        \n",
    "    image_filter = conv_fn(\n",
    "    input=input_image,\n",
    "    filters=krnl,\n",
    "    strides=1,\n",
    "    padding='SAME',\n",
    "    )\n",
    "\n",
    "    return (image_filter.numpy()-np.min(image_filter.numpy()))/(np.max(image_filter.numpy())-np.min(image_filter.numpy())) if normalize else image_filter.numpy()\n",
    "\n",
    "def threshold_over_normalised_image(input_image:np.array, threshold_percent:float, replacement_val:float) -> tf.Tensor:\n",
    "    \"\"\"\n",
    "    Gets the kernel from a dictionary and sets it to the correct shape\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_image : np.array\n",
    "        The image to be filtered over\n",
    "\n",
    "    threshold_percent : float\n",
    "        The percent below which values should be thresholded\n",
    "\n",
    "    replacement_val : float\n",
    "        What value to replace the thresholded values with\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tf.Tensor\n",
    "        Thresholded image with correct shape\n",
    "    \"\"\"\n",
    "    thld = nn.Threshold(np.max(input_image) * threshold_percent, replacement_val)\n",
    "    thld_image = thld(torch.from_numpy(input_image)).numpy()\n",
    "    return tf.squeeze(tf.transpose(thld_image, perm=[1, 2, 0, 3]))\n",
    "\n",
    "\n",
    "def apply_kernels(used_kernels = [\"Edge Detect\"], kernel_names = [\"Edge Detect\"], image_loc = DATA_PATH, image_range = [271, 272], save_location = \"../\", threshold_value=0.540, inverse_image_alphas=False, save_image=False, alpha_bounds=(100,553), verbose=True):\n",
    "    \"\"\"\n",
    "    Applies given kernels over an image, returns the output as an image and optinally saves it.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    used_kernels : list[str, tf.constant]\n",
    "        List of kernels as either strings, tf.constants, or both.\n",
    "\n",
    "    kernel_names : float\n",
    "        The names of the used kernels, which will be used as the titles of images\n",
    "\n",
    "    image_loc : path\n",
    "        The path where the images are located\n",
    "\n",
    "    image_range : list\n",
    "        The range/list of numbers representing the current frame being processed\n",
    "\n",
    "    save_location : string \n",
    "        The location to which the image should be saved\n",
    "    \n",
    "    threshold_value :float \n",
    "        A value, typically in the range [0,1], below which all values will be set to 0\n",
    "    \n",
    "    inverse_image_alphas :bool \n",
    "        Should the alpha (transparency) values be inversed. \n",
    "    \n",
    "    save_image : bool\n",
    "        Should the image be saved\n",
    "    \n",
    "    alpha_bounds : tuple\n",
    "        The row bounds between which the image will be checked for processing.\n",
    "        Useful since our images have lots of unused space.\n",
    "    \n",
    "    verbose: bool\n",
    "        Should every step of preprocessing be shown\n",
    "    \"\"\"\n",
    "    for i in image_range:\n",
    "        if i%500==0:\n",
    "            print(f\"Frame #{i}\")\n",
    "    # for i in tqdm(range(max_number_of_images)):\n",
    "        # Used for image show\n",
    "        # wave_raw = torchvision.transforms.Grayscale(1)(decode_image(str(image_loc / f'{str(i).zfill(5)}.jpg'))/255.0) \n",
    "        wave_raw = decode_image(str(image_loc / f'{str(i).zfill(5)}.jpg'))/255.0\n",
    "        image_list = [wave_raw]\n",
    "        image_names = [\"Raw Image\"] + kernel_names\n",
    "        # Used for processing\n",
    "        processed_image = tf.concat([tf.expand_dims(wave_raw, 3)], 3)\n",
    "        processed_image = tf.math.divide(tf.math.subtract(\n",
    "                                    processed_image, \n",
    "                                    tf.reduce_min(processed_image)\n",
    "                                ), \n",
    "                                tf.math.subtract(\n",
    "                                    tf.reduce_max(processed_image), \n",
    "                                    tf.reduce_min(processed_image)\n",
    "                                ))\n",
    "        \n",
    "        for krn in used_kernels:\n",
    "            processed_image = filter_over_image(processed_image, krn, normalize=True)\n",
    "            image_list.append(processed_image)\n",
    "\n",
    "        # Thresholding\n",
    "        processed_image = threshold_over_normalised_image(processed_image, threshold_value, 0)\n",
    "        global t2_not\n",
    "        t2_not=processed_image\n",
    "        image_list.append(processed_image)\n",
    "        image_names.append(\"thresholed\")\n",
    "        \n",
    "        alphas = np.where(tf.squeeze(processed_image) > 0, 1, 0.0)\n",
    "        ###########################\n",
    "        # Alpha edits for inverse #\n",
    "        if inverse_image_alphas:\n",
    "            alphas = alphas.max() - alphas + alphas.min()\n",
    "        alphas[:alpha_bounds[0], :] = 0\n",
    "        # alphas[553:, :] = 0\n",
    "        alphas[alpha_bounds[1]:, :] = 0\n",
    "        ###########################\n",
    "        ###########################\n",
    "        \n",
    "\n",
    "        ############ Morphological transformations ############\n",
    "        # closing = cv2.morphologyEx(alphas, cv2.MORPH_CLOSE, np.ones((5,5),np.uint8))\n",
    "        # opening = cv2.morphologyEx(alphas, cv2.MORPH_OPEN, np.ones((3,3),np.uint8))\n",
    "        closing = cv2.morphologyEx(alphas, cv2.MORPH_CLOSE, np.ones((3,3),np.uint8))\n",
    "        # closing = cv2.morphologyEx(closing, cv2.MORPH_GRADIENT, np.ones((3,3),np.uint8))\n",
    "        # closing = cv2.morphologyEx(closing, cv2.MORPH_OPEN, np.ones((9,9),np.uint8))\n",
    "        # closing = cv2.morphologyEx(closing, cv2.MORPH_CLOSE, np.ones((5,5),np.uint8))\n",
    "        # closing = cv2.morphologyEx(closing, cv2.MORPH_OPEN, np.ones((5,5),np.uint8))\n",
    "        # closing = cv2.morphologyEx(closing, cv2.MORPH_GRADIENT, np.ones((3,3),np.uint8))\n",
    "\n",
    "        alphas = np.where(tf.squeeze(closing) > 0.0, 1, 0.0)\n",
    "        # closing = alphas\n",
    "        # image_list.append(closing)\n",
    "        image_list.append(closing)\n",
    "        image_names.append(\"with open and close\")\n",
    "        #######################################################\n",
    "        #######################################################\n",
    "\n",
    "        # print(type(tf.expand_dims(closing, 0).numpy()))\n",
    "        # print(test.shape)\n",
    "        # test = closing.astype(np.uint8) * 255\n",
    "        # test2 = test\n",
    "        # print((test2 == test).all())\n",
    "        # # test = tf.expand_dims(test, 0).numpy()\n",
    "        # # test = tf.transpose(tf.expand_dims(test, 0), perm=[1, 2, 0]).numpy()\n",
    "        # print(test.dtype, test.max(), test.shape)\n",
    "        # contours, _ = cv2.findContours(test, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        # cnt = contours[4]\n",
    "        # cv2.drawContours(test, [cnt], 0, (0,255,0), 3)\n",
    "        # print((test2 == test).all())\n",
    "        test = np.zeros(closing.shape)\n",
    "        top_positions = []\n",
    "        # print(closing[251].max())\n",
    "        prev_row = None\n",
    "        for column in range(closing.shape[1]):\n",
    "            val_changed = False\n",
    "            for row in range(alpha_bounds[0], alpha_bounds[1]):\n",
    "                if closing[row][column] > 0:\n",
    "                    # if (prev_row is None or prev_row - 50 <= row <= prev_row + 50):\n",
    "                        test[row][column] = 1\n",
    "                        val_changed = True\n",
    "                        # print(row)\n",
    "                        prev_row = row\n",
    "                        # top_positions.append(row)\n",
    "                        # print(f\"found wave at row {row} column {column}\")\n",
    "                        break\n",
    "            if prev_row is None:\n",
    "                prev_row = alpha_bounds[0]\n",
    "            if not val_changed:\n",
    "                # print(prev_row, column)\n",
    "                test[prev_row][column] = 1\n",
    "            top_positions.append(prev_row)\n",
    "            \n",
    "        for pos in range(1, len(top_positions)):\n",
    "            height_change = top_positions[pos] - top_positions[pos-1]\n",
    "            if height_change == 0:\n",
    "                continue\n",
    "            elif height_change < 0:\n",
    "                test[top_positions[pos]:top_positions[pos-1]+1,pos] = 1\n",
    "            else:\n",
    "                test[top_positions[pos-1]:top_positions[pos]+1,pos] = 1\n",
    "\n",
    "        image_list.append(test)\n",
    "        image_names.append(\"modified contour image\")\n",
    "        image_list.append(test)\n",
    "        image_names.append(\"Combined\")\n",
    "\n",
    "        if verbose:\n",
    "            grid_size_x = math.floor((len(image_list))**(1/2))\n",
    "            grid_size_y = math.ceil((len(image_list))/grid_size_x)  \n",
    "        else:\n",
    "            grid_size_x = 1\n",
    "            grid_size_y = 3 \n",
    "        gs = gridspec.GridSpec(grid_size_x, grid_size_y, bottom=0.1, top=0.45, left=0.1, right=0.66)   \n",
    "        fig = plt.figure()\n",
    "        fig.set_figwidth(55)\n",
    "        fig.set_figheight(55)\n",
    "        \n",
    "        # Process image\n",
    "        verbose_count = 0\n",
    "        for j, krn in enumerate(image_names):\n",
    "            # Display image\n",
    "            if verbose:\n",
    "                ax = fig.add_subplot(gs[(j)//grid_size_y, (j)%grid_size_y])\n",
    "            else:\n",
    "                ax = fig.add_subplot(gs[(verbose_count)//grid_size_y, (verbose_count)%grid_size_y])\n",
    "            if j == 0:\n",
    "                grayscaled_raw = tf.squeeze(image_list[j])*-1\n",
    "                ax.imshow(grayscaled_raw, cmap=\"binary\", alpha = 1)\n",
    "                ax.set_title(f\"Step {j}: {krn}\")\n",
    "                verbose_count += 1\n",
    "\n",
    "            elif j >= len(image_names) -2:\n",
    "                if j == len(image_names) -1:\n",
    "                    ax.imshow(tf.squeeze(image_list[0]), alpha=0.75, cmap='gray')\n",
    "\n",
    "                ax.imshow(tf.squeeze(image_list[j]), alpha = test, cmap=cmap1_strict)\n",
    "                # ax.imshow(tf.squeeze(backup_test), alpha = backup_test, cmap=cmap1_strict)\n",
    "                ax.set_title(f\"Step {j}: {krn}\")\n",
    "                verbose_count += 1\n",
    "\n",
    "            elif verbose:\n",
    "                ax.imshow(tf.squeeze(image_list[j]))\n",
    "                ax.set_title(f\"Step {j}: {krn}\")\n",
    "        \n",
    "        if save_image:\n",
    "            plt.savefig(save_location + f\"output_{i}.png\") # Multi kernels\n",
    "            ax.clear()\n",
    "            fig.clear()\n",
    "            plt.close()\n",
    "    # Transform to correct format:\n",
    "    # $VAR1=0\n",
    "    # $END=7560\n",
    "    # $i=1800\n",
    "    # for ((;i<=END;i+=10)); do mv output_$i.png output_$VAR1.png; VAR1=$(($VAR1+1)); done\n",
    "    # for ((i=1800;i<=END;i+=10)); do mv output_$i.png output_$VAR1.png; VAR1=$(($VAR1+1)); done\n",
    "    # Turn into video: \n",
    "    # ffmpeg -r 60 -f image2 -s 1024x1024 -i output_%d.png -vcodec libx264 -crf 25 test.mp4\n",
    "    # This does not really create github compatible gifs and videos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply kernels, show and/or save final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time can be saved by creating and saving the gaussian filters as a separate variable (think in the same style as the kernels dictionary)\n",
    "my_kernels = [create_gaussian_filter(1.4,2),\"Edge Detect\"]\n",
    "my_kernel_names = [\"Gaussian\", \"Edge Detect\"]\n",
    "# DATA_PATH was defined at the start\n",
    "# my_image_location = DATA_PATH # Path('../../data/raw/test_data')\n",
    "my_image_location = Path('../../data/raw/back_h0_128mm_test015')\n",
    "# image_numbers = range(1800, 15001)\n",
    "# image_numbers = range(1800, 1801)\n",
    "image_numbers = range(4400, 4401)\n",
    "# image_numbers = range(1800, 15001, 20) # An example can be range(0, 708) and it will create a list of 709 values\n",
    "# Another example can be range(1800, 15001, 10), it will go from 1800, 15000 but increase by 10 every step instead of by 1 (1800, 1810, 1820... 14980, 14990, 15000)\n",
    "save_path = '../../Outputs/Multi_Kernel/Gaussian-Edge-Close-Close-Open-Gradient-Backlight/'\n",
    "# threshold_value = 0.32\n",
    "threshold_value = 0.4\n",
    "inverse_image_alphas = False\n",
    "save_image = True\n",
    "verbose = True\n",
    "\n",
    "# for r in tqdm(image_numbers):\n",
    "apply_kernels(used_kernels=my_kernels, kernel_names=my_kernel_names, image_loc=my_image_location, image_range=image_numbers, save_location=save_path,\n",
    "            threshold_value=threshold_value, inverse_image_alphas=inverse_image_alphas, save_image=save_image, alpha_bounds=(200, 750), verbose = verbose)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vaawf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
